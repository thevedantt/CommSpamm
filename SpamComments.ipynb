{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUA1s8hTiEl9MQpStMyj3X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thevedantt/CommSpamm/blob/main/SpamComments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure API Key\n",
        "genai.configure(api_key=\"AIzaSyDOFTjxJN62XqAwexqW4MhGOkRcg96bzrI\")\n",
        "\n",
        "# Load Gemini Flash 2.0 Model\n",
        "gemini = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n"
      ],
      "metadata": {
        "id": "lMpoM9vbkoiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load all CSVs from folder\n",
        "folder_path = \"/content/youtube-spam-collection-v1\"\n",
        "csv_files = glob.glob(folder_path + \"/*.csv\")\n",
        "\n",
        "# Combine all CSVs\n",
        "dataframes = []\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file)[[\"CONTENT\", \"CLASS\"]]\n",
        "    dataframes.append(df)\n",
        "\n",
        "data = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Map class labels\n",
        "data[\"CLASS\"] = data[\"CLASS\"].map({0: \"Not Spam\", 1: \"Spam Comment\"})\n",
        "\n",
        "# Generate synthetic comments using Gemini\n",
        "prompt = \"\"\"Generate 10 spam and 10 non-spam YouTube comments. Format:\n",
        "Spam: \"...\"\n",
        "Not Spam: \"...\" \"\"\"\n",
        "\n",
        "response = gemini.generate_content(prompt)\n",
        "lines = response.text.strip().split('\\n')\n",
        "\n",
        "aug_comments = []\n",
        "aug_labels = []\n",
        "\n",
        "for line in lines:\n",
        "    if \"Spam:\" in line:\n",
        "        aug_comments.append(line.replace(\"Spam:\", \"\").strip().strip('\"'))\n",
        "        aug_labels.append(\"Spam Comment\")\n",
        "    elif \"Not Spam:\" in line:\n",
        "        aug_comments.append(line.replace(\"Not Spam:\", \"\").strip().strip('\"'))\n",
        "        aug_labels.append(\"Not Spam\")\n",
        "\n",
        "# Add augmented data\n",
        "aug_df = pd.DataFrame({\"CONTENT\": aug_comments, \"CLASS\": aug_labels})\n",
        "data = pd.concat([data, aug_df], ignore_index=True)\n",
        "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "hx0IBvxFksC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and labels\n",
        "x = data[\"CONTENT\"]\n",
        "y = data[\"CLASS\"]\n",
        "\n",
        "# Vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "x_vect = vectorizer.fit_transform(x)\n",
        "\n",
        "# Split data\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x_vect, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bernoulli Naive Bayes Model\n",
        "model_nb = BernoulliNB()\n",
        "\n",
        "# Train for 10 epochs\n",
        "for epoch in range(1, 11):\n",
        "    model_nb.partial_fit(xtrain, ytrain, classes=np.unique(y))\n",
        "    preds = model_nb.predict(xtest)\n",
        "    acc = accuracy_score(ytest, preds)\n",
        "    print(f\"Epoch {epoch}/10 - Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2icDDSOfk5ax",
        "outputId": "74516ae4-0c89-4c87-844b-fd47e89e7e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Accuracy: 0.8852\n",
            "Epoch 2/10 - Accuracy: 0.8827\n",
            "Epoch 3/10 - Accuracy: 0.8852\n",
            "Epoch 4/10 - Accuracy: 0.8852\n",
            "Epoch 5/10 - Accuracy: 0.8827\n",
            "Epoch 6/10 - Accuracy: 0.8852\n",
            "Epoch 7/10 - Accuracy: 0.8878\n",
            "Epoch 8/10 - Accuracy: 0.8878\n",
            "Epoch 9/10 - Accuracy: 0.8929\n",
            "Epoch 10/10 - Accuracy: 0.8929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_with_explanation(comment):\n",
        "    # Vectorize the comment\n",
        "    vect_comment = vectorizer.transform([comment])\n",
        "\n",
        "    # Predict with model\n",
        "    proba = model_nb.predict_proba(vect_comment)[0]\n",
        "    pred = model_nb.predict(vect_comment)[0]\n",
        "\n",
        "    # Fallback to Gemini if confidence is low\n",
        "    if max(proba) < 0.6:\n",
        "        print(\"âš ï¸ Low confidence detected. Using Gemini for decision.\")\n",
        "        fallback_prompt = f\"\"\"Classify the following YouTube comment as either 'Spam Comment' or 'Not Spam':\\n\"{comment}\" \"\"\"\n",
        "        gemini_resp = gemini.generate_content(fallback_prompt)\n",
        "        pred = gemini_resp.text.strip()\n",
        "\n",
        "    # Explanation using Gemini\n",
        "    explain_prompt = f\"\"\"Explain why the following YouTube comment might be considered spam or not spam:\\n\"{comment}\" \"\"\"\n",
        "    explanation = gemini.generate_content(explain_prompt).text.strip()\n",
        "\n",
        "    return pred, explanation\n"
      ],
      "metadata": {
        "id": "6BdnPIuVlAxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_comment = \"Subscribe to this channel and win an iPhone!\"\n",
        "label, explanation = classify_with_explanation(test_comment)\n",
        "\n",
        "print(f\"\\nðŸ§¾ Prediction: {label}\\nðŸ§  Explanation: {explanation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "eL8nALyFlE6H",
        "outputId": "386a6e40-c031-4930-fa12-a03a7b6738e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§¾ Prediction: Spam Comment\n",
            "ðŸ§  Explanation: This YouTube comment is very likely **spam**.  Here's why:\n",
            "\n",
            "* **Deceptive Promise:** It uses a tempting offer (\"win an iPhone!\") to lure viewers into subscribing.  There's rarely any legitimate basis for such a giveaway tied directly to a simple subscription.  It's highly probable the commenter is trying to artificially inflate subscriber counts, potentially for monetization purposes or other malicious reasons.\n",
            "\n",
            "* **Lack of Transparency:**  There's no information about how the \"win\" will occur.  Legitimate giveaways typically have clear rules and entry methods. This vagueness is a red flag.\n",
            "\n",
            "* **Common Spam Tactic:**  This type of comment is a classic example of spam used to boost channel metrics.  It's a low-effort, high-volume strategy employed by spam bots and accounts created solely for this purpose.\n",
            "\n",
            "While it's *theoretically* possible the comment is legitimate (e.g., a small creator running a genuine, albeit poorly advertised, giveaway), the overwhelming probability points towards it being spam due to the common nature of this tactic and its manipulative nature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_user_input():\n",
        "    # Take input from user (paragraph or comments)\n",
        "    print(\"Enter your paragraph or multiple YouTube-style comments (separated by dots, newlines, or spaces):\")\n",
        "    user_input = input(\"ðŸ‘‰ \")\n",
        "\n",
        "    # Split into individual comments (basic sentence splitting)\n",
        "    comments = user_input.replace('\\n', '. ').split('. ')\n",
        "    comments = [c.strip() for c in comments if c.strip()]\n",
        "\n",
        "    spam_results = []\n",
        "    vulgar_results = []\n",
        "\n",
        "    for comment in comments:\n",
        "        # Classify spam\n",
        "        vect = vectorizer.transform([comment])\n",
        "        prob = model_nb.predict_proba(vect)[0]\n",
        "        pred = model_nb.predict(vect)[0]\n",
        "\n",
        "        if max(prob) < 0.6:\n",
        "            response = gemini.generate_content(f'Classify the comment as \"Spam Comment\" or \"Not Spam\": \"{comment}\"')\n",
        "            pred = response.text.strip()\n",
        "\n",
        "        # Detect vulgar words\n",
        "        check_vulgar = f\"\"\"Does the following comment contain any vulgar, abusive, or inappropriate words?\n",
        "List them. If none, reply 'None'.\\n\\n\"{comment}\" \"\"\"\n",
        "        vul_response = gemini.generate_content(check_vulgar).text.strip()\n",
        "\n",
        "        spam_results.append((comment, pred))\n",
        "        if vul_response.lower() != \"none\":\n",
        "            vulgar_results.append((comment, vul_response))\n",
        "\n",
        "    return spam_results, vulgar_results\n"
      ],
      "metadata": {
        "id": "YKQRblrZl6iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_detected, vulgar_detected = process_user_input()\n",
        "\n",
        "# Print Results\n",
        "print(\"\\nðŸ” SPAM CLASSIFICATION RESULTS:\")\n",
        "for c, label in spam_detected:\n",
        "    print(f\"â€¢ [{label}] {c}\")\n",
        "\n",
        "print(\"\\nðŸš« VULGARITY DETECTION RESULTS:\")\n",
        "for c, bad_words in vulgar_detected:\n",
        "    print(f\"â€¢ {c}\\n  âš ï¸ Vulgar/Offensive Words: {bad_words}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ixWRSPGDl9WC",
        "outputId": "1c20dab3-443f-440f-c312-05d2cc90c2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your paragraph or multiple YouTube-style comments (separated by dots, newlines, or spaces):\n",
            "ðŸ‘‰ ðŸ‘‰ Hey subscribe to my channel and win a PS5. WTF this is garbage. I love this video. You are a dumb idiot.\n",
            "\n",
            "ðŸ” SPAM CLASSIFICATION RESULTS:\n",
            "â€¢ [Spam Comment] ðŸ‘‰ Hey subscribe to my channel and win a PS5\n",
            "â€¢ [Not Spam] WTF this is garbage\n",
            "â€¢ [Not Spam] I love this video\n",
            "â€¢ [Not Spam] You are a dumb idiot.\n",
            "\n",
            "ðŸš« VULGARITY DETECTION RESULTS:\n",
            "â€¢ WTF this is garbage\n",
            "  âš ï¸ Vulgar/Offensive Words: WTF\n",
            "\n",
            "â€¢ You are a dumb idiot.\n",
            "  âš ï¸ Vulgar/Offensive Words: dumb, idiot\n",
            "\n"
          ]
        }
      ]
    }
  ]
}